# 第一课：书生·浦语大模型全链路开源体系
## 课程内容：
- 通用大模型成为人工智能发展趋势，书生·浦语大模型开源历程，书生·浦语大模型2.0提供不同尺寸和类型的模型，支持多语言和多模态任务。
  - 共有2个参数规格（7B，20B）及三个版本
    - InternLM-Base：高质量高可塑性模型，可在此模型基础上进行微调训练。
    - InternLM：在Base基础上，进行了多种能力的强化，评测中表现优秀，有很好的通用语言能力，推荐大部分应用中使用。
    - InternLM-Chat：面向对话交互进行了优化，具有良好的指令遵循，共情聊天和调用工具的能力。
- 从模型选型到应用的整个流程，以及各个环节需要做的事情，并介绍了书生葡语的全链条工具体系和开源数据集。
  - 模型选型是第一步，需要考虑模型的复杂度和算力。
  - 确定是否需要全量微调或ALoRA微调。
  - 确定是否需要环境交互，构建智能体。
  - 模型评测。
  - 模型部署。
- 书生·万卷开放高质量语料数据：2TB数据量。
- 预训练：高可扩展、极致性能优化、兼容主流、开箱即用。
- 高效微调框架XTuner：增量续训（文章、书籍、代码）。有监督微调（高质量对话，问答数据）。最低只需8GB显存可微调7B模型。
- OpenCompass 2.0思南大模型评测体系，包括评测框架的开发和开源、评测基准社区的建立以及对大模型能力提升的分析。
- LMDeploy部署工具：多用接口、轻量化、服务模块（工具链）
- 轻量级智能体框架Lagent：支持多种类型的智能体能力，灵活支持多种大语言模型，简单易拓展，支持丰富的工具。
- 多模态智能体工具箱 AgentLego：支持多模态，支持主流智能体系统，一键式远程部署。
